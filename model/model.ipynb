{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2 as cv\n",
    "import torch\n",
    "import torchvision\n",
    "import torchsummary\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch import utils\n",
    "import pandas as pd\n",
    "#import torchmetrics\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_images_cv(path, masked = False):\n",
    "  \"\"\"\n",
    "  open images concurrently by using a thread pool\n",
    "  \"\"\"\n",
    "  temp = []\n",
    "  def read_image(image):\n",
    "    return cv.resize(cv.cvtColor(cv.imread(os.path.join(path,image)), cv.COLOR_BGR2RGB),(128,128))\n",
    "\n",
    "\n",
    "  images = os.listdir(path)\n",
    "  images=sorted(images)\n",
    "  if masked==True:\n",
    "    images = [entry for entry in images if \"road\" in entry]\n",
    "\n",
    "  with ThreadPoolExecutor() as executor:\n",
    "    files = executor.map(read_image,images)\n",
    "    for f in files:\n",
    "      temp.append(np.asarray(f))\n",
    "  return np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_paths(path: str):\n",
    "    train_data_dir = f\"{path}/dataset/training/image_2/\"\n",
    "    train_gt_dir = f\"{path}/dataset/training/gt_image_2/\"\n",
    "\n",
    "    test_data_dir = f\"{path}/dataset/testing/\"\n",
    "    return train_data_dir, train_gt_dir, test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir, train_gt_dir, test_data_dir = load_dataset_paths('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=open_images_cv(train_data_dir,masked=False)\n",
    "masks=open_images_cv(train_gt_dir,masked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_validation_split(data : np.ndarray, true_masks: np.ndarray,train_size = 0.8):\n",
    "    \"\"\"\n",
    "    Splits dataset onto train, test, and validation datasets\n",
    "    \"\"\"\n",
    "    train_set_size = int(len(data) * train_size)\n",
    "    validation_set_size = int(len(data) * 0.1)\n",
    "    test_set_size = len(data) - train_set_size - validation_set_size\n",
    "    \n",
    "    X_test=data[:test_set_size].transpose((0, 3, 1, 2))\n",
    "    y_test=true_masks[:test_set_size].transpose((0, 3, 1, 2))\n",
    "\n",
    "\n",
    "    data=data[test_set_size:]\n",
    "    true_masks=true_masks[test_set_size:]\n",
    "\n",
    "    # shuffle\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    shuffled_data = data[shuffled_indices]\n",
    "    shuffled_masks = true_masks[shuffled_indices]\n",
    "\n",
    "    X_train=shuffled_data[:train_set_size].transpose((0, 3, 1, 2))\n",
    "    y_train=shuffled_masks[:train_set_size].transpose((0, 3, 1, 2))\n",
    "\n",
    "    X_val=shuffled_data[train_set_size:train_set_size+validation_set_size].transpose((0, 3, 1, 2))\n",
    "    y_val=shuffled_masks[train_set_size:train_set_size+validation_set_size].transpose((0, 3, 1, 2))\n",
    "\n",
    "\n",
    "    return X_train, y_train, X_test, y_test , X_val, y_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test , X_val, y_val  = test_train_validation_split(data,binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images,masks):\n",
    "        self.images=images\n",
    "        self.masks=masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image= self.images[index]\n",
    "        mask=self.masks[index]\n",
    "        return image,mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(X_train,y_train)\n",
    "val_dataset = ImageDataset(X_val, y_val)\n",
    "test_dataset = ImageDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "val_dataloader=DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader=DataLoader(test_dataset, batch_size=64,shuffle=False)\n",
    "\n",
    "print(f\"Train dataloader length: {len(train_dataloader)} batches of size {64}\")\n",
    "print(f\"Validation dataloader length: {len(val_dataloader)} batches of size {64}\")\n",
    "print(f\"Test dataloader length: {len(test_dataloader)} batches of size {64}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
